{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebc260cd-3be1-4644-8a97-c3eab31bb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using \"student-por.csv\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6ffcc91-f428-4ffd-9448-c0c56038cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese Shape: (649, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to your folder\n",
    "path = '../data/student-por.csv'\n",
    "\n",
    "# Load the Portuguese students\n",
    "df_por = pd.read_csv(path, sep=';')\n",
    "\n",
    "# Check if it loaded correctly\n",
    "print(f\"Portuguese Shape: {df_por.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cdd94d8-48e7-4ce9-8d69-912671625bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        4   0  11  11  \n",
       "1      5        3      3     1     1      3        2   9  11  11  \n",
       "2      4        3      2     2     3      3        6  12  13  12  \n",
       "3      3        2      2     1     1      5        0  14  14  14  \n",
       "4      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_por.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c6b0617-ed19-4310-b038-67758bb9d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school        object\n",
      "sex           object\n",
      "age            int64\n",
      "address       object\n",
      "famsize       object\n",
      "Pstatus       object\n",
      "Medu           int64\n",
      "Fedu           int64\n",
      "Mjob          object\n",
      "Fjob          object\n",
      "reason        object\n",
      "guardian      object\n",
      "traveltime     int64\n",
      "studytime      int64\n",
      "failures       int64\n",
      "schoolsup     object\n",
      "famsup        object\n",
      "paid          object\n",
      "activities    object\n",
      "nursery       object\n",
      "higher        object\n",
      "internet      object\n",
      "romantic      object\n",
      "famrel         int64\n",
      "freetime       int64\n",
      "goout          int64\n",
      "Dalc           int64\n",
      "Walc           int64\n",
      "health         int64\n",
      "absences       int64\n",
      "G1             int64\n",
      "G2             int64\n",
      "G3             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types for all columns\n",
    "print(df_por.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "445b9156-b77b-4a21-ac89-cb0f10cfb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "G1            0\n",
      "G2            0\n",
      "G3            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "missing_values = df_por.isnull().sum()\n",
    "\n",
    "# Display the counts\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66204a90-4146-4d2c-bb5b-ad2ef1dd278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3467a916-1a19-47d8-9d5f-f0a4a8fa1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (649, 33)\n",
      "Exact Duplicate Rows: 0\n",
      "Duplicate Student Profiles (ignoring grades): 0\n",
      "\n",
      "Cleaned Column Names:\n",
      "['school', 'sex', 'age', 'address', 'fam_size', 'p_status', 'm_edu', 'f_edu', 'm_job', 'f_job', 'reason', 'guardian', 'travel_time', 'study_time', 'failures', 'school_sup', 'fam_sup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'fam_rel', 'free_time', 'go_out', 'd_alc', 'w_alc', 'health', 'absences', 'g1', 'g2', 'g3']\n"
     ]
    }
   ],
   "source": [
    "# Mapping for snake_case (PEP 8 compliance)\n",
    "# This addresses CamelCase (Pstatus), combined words (studytime), and lowercase (G1)\n",
    "rename_map = {\n",
    "    'famsize': 'fam_size',\n",
    "    'Pstatus': 'p_status',\n",
    "    'Medu': 'm_edu',\n",
    "    'Fedu': 'f_edu',\n",
    "    'Mjob': 'm_job',\n",
    "    'Fjob': 'f_job',\n",
    "    'traveltime': 'travel_time',\n",
    "    'studytime': 'study_time',\n",
    "    'schoolsup': 'school_sup',\n",
    "    'famsup': 'fam_sup',\n",
    "    'famrel': 'fam_rel',\n",
    "    'freetime': 'free_time',\n",
    "    'goout': 'go_out',\n",
    "    'Dalc': 'd_alc',\n",
    "    'Walc': 'w_alc',\n",
    "    'G1': 'g1',\n",
    "    'G2': 'g2',\n",
    "    'G3': 'g3'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "df_por.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Ensure all other columns are lowercase (just in case)\n",
    "df_por.columns = [c.lower() for c in df_por.columns]\n",
    "\n",
    "# 1. Check for exact row duplicates\n",
    "exact_duplicates = df_por.duplicated().sum()\n",
    "\n",
    "# 2. Check for duplicate student profiles (ignoring grades)\n",
    "profile_cols = [col for col in df_por.columns if col not in ['g1', 'g2', 'g3']]\n",
    "profile_duplicates = df_por.duplicated(subset=profile_cols).sum()\n",
    "\n",
    "print(f\"Dataset Shape: {df_por.shape}\")\n",
    "print(f\"Exact Duplicate Rows: {exact_duplicates}\")\n",
    "print(f\"Duplicate Student Profiles (ignoring grades): {profile_duplicates}\")\n",
    "print(\"\\nCleaned Column Names:\")\n",
    "print(df_por.columns.tolist())\n",
    "\n",
    "# Save the cleaned data\n",
    "df_por.to_csv('student_por_cleaned_n1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "124c976b-ed22-4aaa-becd-b954d059b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>fam_size</th>\n",
       "      <th>p_status</th>\n",
       "      <th>m_edu</th>\n",
       "      <th>f_edu</th>\n",
       "      <th>m_job</th>\n",
       "      <th>f_job</th>\n",
       "      <th>...</th>\n",
       "      <th>fam_rel</th>\n",
       "      <th>free_time</th>\n",
       "      <th>go_out</th>\n",
       "      <th>d_alc</th>\n",
       "      <th>w_alc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address fam_size p_status  m_edu  f_edu    m_job     f_job  \\\n",
       "0     GP   F   18       U      GT3        A      4      4  at_home   teacher   \n",
       "1     GP   F   17       U      GT3        T      1      1  at_home     other   \n",
       "2     GP   F   15       U      LE3        T      1      1  at_home     other   \n",
       "3     GP   F   15       U      GT3        T      4      2   health  services   \n",
       "4     GP   F   16       U      GT3        T      3      3    other     other   \n",
       "\n",
       "   ... fam_rel free_time  go_out  d_alc  w_alc health absences  g1  g2  g3  \n",
       "0  ...       4         3       4      1      1      3        4   0  11  11  \n",
       "1  ...       5         3       3      1      1      3        2   9  11  11  \n",
       "2  ...       4         3       2      2      3      3        6  12  13  12  \n",
       "3  ...       3         2       2      1      1      5        0  14  14  14  \n",
       "4  ...       4         3       2      1      2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_por.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "221db047-c6b4-4639-8be5-af3c2c6a751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cba16a5-4d38-4587-bcba-2cc0dc4bcfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLeaned Portuguese Shape: (649, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>fam_size</th>\n",
       "      <th>p_status</th>\n",
       "      <th>m_edu</th>\n",
       "      <th>f_edu</th>\n",
       "      <th>m_job</th>\n",
       "      <th>f_job</th>\n",
       "      <th>...</th>\n",
       "      <th>fam_rel</th>\n",
       "      <th>free_time</th>\n",
       "      <th>go_out</th>\n",
       "      <th>d_alc</th>\n",
       "      <th>w_alc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address fam_size p_status  m_edu  f_edu    m_job     f_job  \\\n",
       "0     GP   F   18       U      GT3        A      4      4  at_home   teacher   \n",
       "1     GP   F   17       U      GT3        T      1      1  at_home     other   \n",
       "2     GP   F   15       U      LE3        T      1      1  at_home     other   \n",
       "3     GP   F   15       U      GT3        T      4      2   health  services   \n",
       "4     GP   F   16       U      GT3        T      3      3    other     other   \n",
       "\n",
       "   ... fam_rel free_time  go_out  d_alc  w_alc health absences  g1  g2  g3  \n",
       "0  ...       4         3       4      1      1      3        4   0  11  11  \n",
       "1  ...       5         3       3      1      1      3        2   9  11  11  \n",
       "2  ...       4         3       2      2      3      3        6  12  13  12  \n",
       "3  ...       3         2       2      1      1      5        0  14  14  14  \n",
       "4  ...       4         3       2      1      2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the cleaned data in folder\n",
    "path = '../notebooks/student_por_cleaned_n1.csv'\n",
    "\n",
    "# Load the Cleaned Portuguese students\n",
    "df_por = pd.read_csv(path, sep=',')\n",
    "\n",
    "# Check if it loaded correctly\n",
    "print(f\"CLeaned Portuguese Shape: {df_por.shape}\")\n",
    "df_por.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e32892a8-6b65-4e1f-a0e9-f589ff4ee5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Categorical and Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d798c675-ec05-4a72-bafd-8b05dd62ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: 16\n",
      "Categorical columns: 17\n"
     ]
    }
   ],
   "source": [
    "# Separate Numerical columns\n",
    "# includes: age, absences, g1, g2, g3, and the 1-5 scales (medu, fedu, travel_time, etc.)\n",
    "df_numeric = df_por.select_dtypes(include=['number'])\n",
    "\n",
    "# Separate Categorical columns\n",
    "# includes: school, sex, address, m_job, f_job, reason, guardian, and all yes/no columns\n",
    "df_categorical = df_por.select_dtypes(include=['object'])\n",
    "\n",
    "print(f\"Numerical columns: {df_numeric.shape[1]}\")\n",
    "print(f\"Categorical columns: {df_categorical.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2e2bcec-3b13-46b9-9fac-8a4e10be4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify which columns went where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "643f9de9-57a8-4620-b86e-c540db8493fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Numerical Features ---\n",
      "['age', 'm_edu', 'f_edu', 'travel_time', 'study_time', 'failures', 'fam_rel', 'free_time', 'go_out', 'd_alc', 'w_alc', 'health', 'absences', 'g1', 'g2', 'g3']\n",
      "\n",
      "--- Categorical Features ---\n",
      "['school', 'sex', 'address', 'fam_size', 'p_status', 'm_job', 'f_job', 'reason', 'guardian', 'school_sup', 'fam_sup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Numerical Features ---\")\n",
    "print(df_numeric.columns.tolist())\n",
    "\n",
    "print(\"\\n--- Categorical Features ---\")\n",
    "print(df_categorical.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb33f4cc-6879-4b0e-a0b6-bc6f9e07f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prepare the Portuguese dataset for analysis or machine learning, apply different techniques: Scaling for numerical data and Encoding for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a62340cb-b0b4-4d61-aadc-08427e3169df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Binary Encoding (Yes/No to 1/0)\n",
    "binary_cols = [col for col in df_categorical.columns if df_por[col].nunique() == 2]\n",
    "for col in binary_cols:\n",
    "    df_por[col] = df_por[col].astype('category').cat.codes\n",
    "\n",
    "# 2. One-Hot Encoding (Multiple categories)\n",
    "nominal_cols = [col for col in df_categorical.columns if df_por[col].nunique() > 2]\n",
    "df_por = pd.get_dummies(df_por, columns=nominal_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0290c6ea-7aca-40ba-b1db-087deb25067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# We usually scale everything except the target variable (G3)\n",
    "features_to_scale = df_numeric.columns.difference(['g3'])\n",
    "\n",
    "df_por[features_to_scale] = scaler.fit_transform(df_por[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1bc86828-60b3-4732-9043-fc24de6ffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML model for predicting student performance\n",
    "#define the Target ( y ) and Features ( X ) and split the data into Training and Testing sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0ba4fa9-21ee-4a3e-85bc-c09d276f4f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (519, 41)\n",
      "Testing set size: (130, 41)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Identify column types automatically\n",
    "numeric_cols = df_por.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_cols = df_por.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 2. Apply One-Hot Encoding to categorical data\n",
    "# drop_first=True prevents the \"Dummy Variable Trap\" (multicollinearity)\n",
    "df_final = pd.get_dummies(df_por, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# 3. Define Features (X) and Target (y)\n",
    "# We use 'g3' (final grade) as our target variable\n",
    "X = df_final.drop('g3', axis=1)\n",
    "y = df_final['g3']\n",
    "\n",
    "# 4. Split the data into Training (80%) and Testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Scale the Numerical Features\n",
    "# We fit the scaler ONLY on the training data to avoid data leakage\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Get only the original numeric columns (excluding the target g3)\n",
    "cols_to_scale = [c for c in numeric_cols if c != 'g3']\n",
    "\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61215bb7-e826-4a82-b631-18c552f6e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize the models\n",
    "lr_model = LinearRegression()\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the models\n",
    "lr_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "rf_preds = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62e2ce41-cf0b-4d9a-8846-b3eb4cc477c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0aeaaa55-1aee-487e-a5f8-16991fe88fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "- MAE: 0.76\n",
      "- RMSE: 1.25\n",
      "- R2 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation for Random Forest\n",
    "mae = mean_absolute_error(y_test, rf_preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, rf_preds))\n",
    "r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Random Forest Metrics:\")\n",
    "print(f\"- MAE: {mae:.2f}\")\n",
    "print(f\"- RMSE: {rmse:.2f}\")\n",
    "print(f\"- R2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e643d-39fb-4494-b7d2-c92626a1633c",
   "metadata": {},
   "source": [
    "Social Model: Drop G1 & G2\n",
    "\n",
    "train a \"Social Model,\" we intentionally remove the grade columns ( g1  and  g2 ) from our features.\n",
    "\n",
    "We drop  g1  and  g2  from our feature set  X . We keep  g3  as our target  y ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89014e49-0a82-45fe-8331-29a98168b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the intermediate grades to focus purely on social/demographic factors\n",
    "X_social = df_final.drop(['g1', 'g2', 'g3'], axis=1)\n",
    "y = df_final['g3']\n",
    "\n",
    "# Split the data\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_social, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae10322-ad85-4a55-9f85-8da0927675e7",
   "metadata": {},
   "source": [
    "Training and Identifying \"Early Warning\" Signs\n",
    "\n",
    "Without the \"crutch\" of previous grades, the model will rely on social features. We can use a Random Forest to see which lifestyle factors rise to the top.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6eff38a-285c-49fa-91ec-d7674c531dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "social_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "social_model.fit(X_train_s, y_train_s)\n",
    "\n",
    "# Extract importance\n",
    "importances = social_model.feature_importances_\n",
    "indices = np.argsort(importances)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26cec67-e552-46b7-88a5-3a3cfb9ef166",
   "metadata": {},
   "source": [
    "To evaluate the \"drop\" in accuracy, we will compare the Full Model (which includes the \"cheating\" variables  g1  and  g2 ) against the Social Model (which only uses demographic and lifestyle data).In the world of educational data science, this \"drop\" represents the transition from a descriptive model (explaining what happened) to a proactive model (forecasting what might happen).\n",
    "\n",
    "Comparative Analysis Script\n",
    "\n",
    "The following code runs both models on the same test split and calculates the metrics side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb7f7185-b9a2-4623-8f56-d671b0843483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Metric  Full Model  Social Model\n",
      "0            MAE (Average Error)    0.756154      2.051769\n",
      "1  R2 Score (Variance Explained)    0.838707      0.188504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. Full Model (with G1 and G2)\n",
    "full_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "full_model.fit(X_train, y_train)\n",
    "full_preds = full_model.predict(X_test)\n",
    "\n",
    "# 2. Social Model (without G1 and G2)\n",
    "social_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "social_model.fit(X_train_s, y_train_s)\n",
    "social_preds = social_model.predict(X_test_s)\n",
    "\n",
    "# Evaluation Results\n",
    "results = {\n",
    "    \"Metric\": [\"MAE (Average Error)\", \"R2 Score (Variance Explained)\"],\n",
    "    \"Full Model\": [mean_absolute_error(y_test, full_preds), r2_score(y_test, full_preds)],\n",
    "    \"Social Model\": [mean_absolute_error(y_test_s, social_preds), r2_score(y_test_s, social_preds)]\n",
    "}\n",
    "\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e74509-8998-4d79-a618-dda142c6c8ea",
   "metadata": {},
   "source": [
    "On Full Model\n",
    "\n",
    "Cross-Validation (The \"Check\")\n",
    "\n",
    "Instead of relying on a single train/test split, k-fold Cross-Validation splits the data into  k  parts (usually 5 or 10). It trains the model  k  times, each time using a different part as the \"test set.\"This gives us a much more reliable estimate of how the model will perform on data it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ae066f7-6803-4770-872b-6e4cb50ff544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R2 Score: 0.78\n",
      "Standard Deviation: 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Check the stability of our Random Forest\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"Mean R2 Score: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation: {cv_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5fe25-3c01-4934-bb4a-5163b256ef20",
   "metadata": {},
   "source": [
    "Grid Search (The \"Optimization\")\n",
    "\n",
    "Random Forest has \"knobs\" we can turn, called hyperparameters. Examples include:\n",
    "\n",
    "n_estimators: How many trees to grow.\n",
    "\n",
    "max_depth: How deep each tree can go.\n",
    "\n",
    "min_samples_split: How many samples are needed to split a node.\n",
    "\n",
    "Grid Search exhaustively tries every combination of these settings to find the \"sweet spot\" that minimizes error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72dfd186-a4f4-48c3-b6d1-2e38dd3e465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the \"Grid\" of parameters to try\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
    "                           cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Fit to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904dada-4505-4872-b9b1-34fa03f2c1ff",
   "metadata": {},
   "source": [
    "Evaluating the Fine-Tuned Model\n",
    "\n",
    "Once Grid Search finishes, it provides the best_estimator_. We compare this tuned model against our original \"out-of-the-box\" model to see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d540035-b93b-4e81-9a3c-0280ba99f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned MAE: 0.88\n",
      "Tuned R2: 0.81\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "tuned_preds = best_rf.predict(X_test)\n",
    "\n",
    "print(f\"Tuned MAE: {mean_absolute_error(y_test, tuned_preds):.2f}\")\n",
    "print(f\"Tuned R2: {r2_score(y_test, tuned_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d21dcd-ecec-407e-a26a-ba8181e7f276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
