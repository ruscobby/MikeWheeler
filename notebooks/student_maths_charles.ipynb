{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3727d8a-8754-4d53-928d-06389d8973f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use raw string to avoid issues with backslashes\n",
    "df = pd.read_csv(\"../data/student-mat.csv\", sep=';')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2facf0-33fd-4b28-93f0-f80709f3cef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd2a88-0632-4c36-8b46-a12fcdf0d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ff1cd-2760-435e-a69e-5e754433ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb6ceb-1768-461f-8e3c-9f13d19683bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cc09d-dde1-497b-8b49-6f99d6d1ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432de38-8d47-4fe1-bc1e-e3cdbf9bbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758b150-a8e2-4b27-bdfa-a611db9749a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['G3'], bins=20, kde=True)\n",
    "plt.title('Distribution of Final Grades (G3)')\n",
    "plt.xlabel('Final Grade')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean G3:\", df['G3'].mean())\n",
    "print(\"Min/Max G3:\", df['G3'].min(), df['G3'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b784f-5396-4145-af45-6bd324a17f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d11e8b-0c24-4210-9e24-1373a7accccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['past_grade_avg'] = (df_clean['G1'] + df_clean['G2']) / 2\n",
    "\n",
    "\n",
    "df_clean['absence_rate'] = df_clean['absences'] / (df_clean['studytime'] + 1)\n",
    "\n",
    "\n",
    "df_clean['failures_binary'] = (df_clean['failures'] > 0).astype(int)\n",
    "\n",
    "\n",
    "df_clean['study_effort'] = df_clean['studytime'] * df_clean['past_grade_avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2dd103-347d-4b6a-b67d-00a04cfcbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df_clean.select_dtypes(include='object').columns\n",
    "print(\"Categorical columns:\", list(categorical_cols))\n",
    "\n",
    "\n",
    "df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"Shape after encoding:\", df_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fe188-9d75-4b4a-9be5-0f126a003f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df_encoded.drop(columns=['G3'])\n",
    "y = df_encoded['G3']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9f730-5050-44d1-a55d-bcfacd0e9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df[\"past_grade_avg\"] = (df[\"G1\"] + df[\"G2\"]) / 2\n",
    "df[\"absence_rate\"] = df[\"absences\"] / df[\"absences\"].max()\n",
    "df[\"failures_binary\"] = (df[\"failures\"] > 0).astype(int)\n",
    "df[\"study_effort\"] = df[\"studytime\"] * df[\"goout\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3f2a9-cb0a-4343-9794-e02550996528",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df[\"past_grade_avg\"], bins=15)\n",
    "plt.title(\"Distribution of Past Grade Average\")\n",
    "plt.xlabel(\"Past Grade Average\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3cf2cc-b30a-4b07-b1a1-b624bd3042b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df[\"absence_rate\"], bins=15)\n",
    "plt.title(\"Distribution of Absence Rate\")\n",
    "plt.xlabel(\"Absence Rate\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1625e4-df1d-4823-a15c-85ad4d1c4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "df[\"failures_binary\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Failures (Binary)\")\n",
    "plt.xlabel(\"Failure (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb10b65-31b1-47cb-96b4-c7f47d54026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df[\"study_effort\"], bins=15)\n",
    "plt.title(\"Distribution of Study Effort\")\n",
    "plt.xlabel(\"Study Effort Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcd35f-afcb-4e7b-a035-95881d1a71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(df[\"past_grade_avg\"], df[\"G3\"], alpha=0.6)\n",
    "plt.title(\"Past Grade Average vs Final Grade\")\n",
    "plt.xlabel(\"Past Grade Average\")\n",
    "plt.ylabel(\"Final Grade (G3)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8da56-6ebb-4da2-9330-7fb8b10c36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Linear Regression Performance\")\n",
    "print(f\"MAE:  {lr_mae:.2f}\")\n",
    "print(f\"RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"R²:   {lr_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbe3b2-518e-4db6-b552-dc027adfcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize model\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "dt_mae = mean_absolute_error(y_test, y_pred_dt)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "dt_r2 = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Performance\")\n",
    "print(f\"MAE:  {dt_mae:.2f}\")\n",
    "print(f\"RMSE: {dt_rmse:.2f}\")\n",
    "print(f\"R²:   {dt_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff074f-44d4-45b9-9fe4-1b61defa5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validation for Linear Regression\n",
    "lr_cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Cross-validation for Decision Tree\n",
    "dt_cv_scores = cross_val_score(dt_model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(\"Cross-Validation R² Scores\")\n",
    "print(f\"Linear Regression CV Mean: {lr_cv_scores.mean():.3f}\")\n",
    "print(f\"Decision Tree CV Mean:     {dt_cv_scores.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d9c7e-c167-4d0c-aa1d-5d7eb4295d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.7)\n",
    "plt.plot([0, 20], [0, 20])\n",
    "plt.xlabel(\"Actual G3\")\n",
    "plt.ylabel(\"Predicted G3\")\n",
    "plt.title(\"Linear Regression: Actual vs Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa04e5f-8b69-4f0e-80ac-3564a4a8597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Performance\")\n",
    "print(f\"MAE:  {rf_mae:.2f}\")\n",
    "print(f\"RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"R²:   {rf_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b14f9-e845-4c35-a729-01752f4d3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "gb_mae = mean_absolute_error(y_test, y_pred_gb)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "gb_r2 = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting Performance\")\n",
    "print(f\"MAE:  {gb_mae:.2f}\")\n",
    "print(f\"RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"R²:   {gb_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a794603-ff42-4fff-bb61-6dafeec28d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\", \"Gradient Boosting\"],\n",
    "    \"MAE\": [rf_mae, gb_mae],\n",
    "    \"RMSE\": [rf_rmse, gb_rmse],\n",
    "    \"R2\": [rf_r2, gb_r2]\n",
    "})\n",
    "\n",
    "advanced_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3775e-65fc-468d-bd3f-87e30c57d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV R² Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba670d-60fc-4aba-a5fb-3020ba1be0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924310ac-8af9-46a7-ad79-6df00286c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Ensure best_rf exists\n",
    "if 'best_rf' not in globals():\n",
    "    best_rf = rf_model\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_mae = mean_absolute_error(y_test, y_pred_best)\n",
    "best_rmse = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "best_r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "best_r2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf894b-3385-400e-8400-6bc9ba2d0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(\n",
    "    best_rf.feature_importances_,\n",
    "    index=X.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "importances.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7572a2-7fe4-4d0d-9c33-4e2bcc60e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.head(10).plot(kind=\"barh\", figsize=(7,5))\n",
    "plt.title(\"Top 10 Most Important Features\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b867d-c68d-4761-802f-ae72d2224680",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.7)\n",
    "plt.plot([0, 20], [0, 20])\n",
    "plt.xlabel(\"Actual G3\")\n",
    "plt.ylabel(\"Predicted G3\")\n",
    "plt.title(\"Final Model: Actual vs Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36118f21-7875-4514-ba26-e0eb63f9e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = best_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21907b8e-49a4-46a9-bfa4-ffa96317b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.7)\n",
    "plt.plot([0, 20], [0, 20])  # perfect prediction line\n",
    "plt.xlabel(\"Actual G3\")\n",
    "plt.ylabel(\"Predicted G3\")\n",
    "plt.title(\"Random Forest: Actual vs Predicted\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a2408-dc14-4ec7-b7a1-04867f7cfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "categorical_cols = df.select_dtypes(include=\"object\").columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Identify one-hot encoded columns\n",
    "encoded_cols = [col for col in df_encoded.columns if \"_\" in col]\n",
    "\n",
    "# Count occurrences\n",
    "encoded_counts = df_encoded[encoded_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "# Plot top 15 encoded features\n",
    "plt.figure(figsize=(8,5))\n",
    "encoded_counts.head(15).plot(kind=\"bar\")\n",
    "plt.title(\"Top 15 One-Hot Encoded Categorical Features\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Encoded Feature\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39231f8f-3f8a-450c-b9e8-45ac61fbcddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Gradient Boosting\",\n",
    "        \"Tuned Random Forest\"\n",
    "    ],\n",
    "    \"R2\": [\n",
    "        lr_r2,\n",
    "        dt_r2,\n",
    "        rf_r2,\n",
    "        gb_r2,\n",
    "        best_r2\n",
    "    ]\n",
    "})\n",
    "\n",
    "final_summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
